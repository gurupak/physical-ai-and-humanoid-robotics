"use strict";(self.webpackChunkhackathon_book=self.webpackChunkhackathon_book||[]).push([[9482],{2552:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>r,toc:()=>c});const r=JSON.parse('{"id":"module-2-digital-twin/unity-rendering/unity-rendering","title":"03. Visual Simulation with Unity","description":"Build photorealistic environments for computer vision and human-robot interaction","source":"@site/docs/module-2-digital-twin/03-unity-rendering/index.md","sourceDirName":"module-2-digital-twin/03-unity-rendering","slug":"/module-2-digital-twin/unity-rendering/","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/unity-rendering/","draft":false,"unlisted":false,"editUrl":"https://github.com/gurupak/physical-ai-and-humanoid-robotics/tree/main/docs/module-2-digital-twin/03-unity-rendering/index.md","tags":[],"version":"current","frontMatter":{"id":"unity-rendering","title":"03. Visual Simulation with Unity","description":"Build photorealistic environments for computer vision and human-robot interaction","sidebar_label":"03. Unity Visuals","readingTime":25},"sidebar":"tutorialSidebar","previous":{"title":"02. Gazebo Physics","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/gazebo-physics/"},"next":{"title":"04. Integration Best Practices","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/integration"}}');var t=i(4848),a=i(8453);const o={id:"unity-rendering",title:"03. Visual Simulation with Unity",description:"Build photorealistic environments for computer vision and human-robot interaction",sidebar_label:"03. Unity Visuals",readingTime:25},s="03. Visual Simulation with Unity",l={},c=[{value:"Why Visual Simulation Matters",id:"why-visual-simulation-matters",level:2},{value:"Setting Up Your First Unity Project",id:"setting-up-your-first-unity-project",level:2},{value:"1. Create a New Unity Project",id:"1-create-a-new-unity-project",level:3},{value:"2. Import the Robotics Package",id:"2-import-the-robotics-package",level:3},{value:"3. The Simplest Scene Setup",id:"3-the-simplest-scene-setup",level:3},{value:"4. Add Some Props",id:"4-add-some-props",level:3},{value:"Training Data Generation",id:"training-data-generation",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...e.components};return(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(n.header,{children:(0,t.jsx)(n.h1,{id:"03-visual-simulation-with-unity",children:"03. Visual Simulation with Unity"})}),"\n",(0,t.jsx)(n.p,{children:"Unity creates stunning visual environments that look like real camera footage. This is perfect for training AI systems and human collaborations."}),"\n",(0,t.jsx)(n.h2,{id:"why-visual-simulation-matters",children:"Why Visual Simulation Matters"}),"\n",(0,t.jsx)(n.p,{children:"Real computer vision training data is expensive:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Cameras cost hundreds or thousands of dollars"}),"\n",(0,t.jsx)(n.li,{children:"Manually labeling thousands of images takes weeks"}),"\n",(0,t.jsx)(n.li,{children:"Lighting conditions are hard to control"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:["Unity solves this: ",(0,t.jsx)(n.strong,{children:"Generate unlimited perfect training data instantly."})]}),"\n",(0,t.jsx)(n.h2,{id:"setting-up-your-first-unity-project",children:"Setting Up Your First Unity Project"}),"\n",(0,t.jsx)(n.h3,{id:"1-create-a-new-unity-project",children:"1. Create a New Unity Project"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Install Unity Hub if you haven't already"}),"\n",(0,t.jsx)(n.li,{children:"Create a new 3D project with Universal Render Pipeline (URP)"}),"\n",(0,t.jsx)(n.li,{children:'Name it "RobotVisionTraining"'}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"2-import-the-robotics-package",children:"2. Import the Robotics Package"}),"\n",(0,t.jsx)(n.p,{children:"Unity has official robotics support:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:"// Package Manager -> Add package from Git URL\r\ncom.unity.robotics.ros-tcp-connector\n"})}),"\n",(0,t.jsx)(n.h3,{id:"3-the-simplest-scene-setup",children:"3. The Simplest Scene Setup"}),"\n",(0,t.jsx)(n.p,{children:"Create a basic warehouse scene:"}),"\n",(0,t.jsxs)(n.ol,{children:["\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Floor"}),": GameObject -> 3D Object -> Plane (scale 10x10)"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Robot"}),": Right-click in Hierarchy -> Import Camera"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Lighting"}),": Window -> Rendering -> Lighting Settings"]}),"\n",(0,t.jsxs)(n.li,{children:[(0,t.jsx)(n.strong,{children:"Camera"}),": Position 5 meters above ground, look down"]}),"\n"]}),"\n",(0,t.jsx)(n.h3,{id:"4-add-some-props",children:"4. Add Some Props"}),"\n",(0,t.jsx)(n.p,{children:"Instantiate a few boxes from Unity Asset Store:"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Get free Robot Factory assets"}),"\n",(0,t.jsx)(n.li,{children:"Add 5-10 cardboard boxes"}),"\n",(0,t.jsx)(n.li,{children:"Position randomly around the floor"}),"\n"]}),"\n",(0,t.jsx)(n.h2,{id:"training-data-generation",children:"Training Data Generation"}),"\n",(0,t.jsx)(n.p,{children:"With Unity ROS, stream camera data directly to ROS2:"}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\r\nusing Unity.Robotics.ROSTCPConnector.ROSGeometry;\r\n\r\npublic class CameraPublisher : MonoBehaviour\r\n{\r\n    [SerializeField] Camera targetCamera;\r\n    [SerializeField] string topicName = "/camera/image";\r\n    [SerializeField] string frameId = "camera_link";\r\n\r\n    void Start()\r\n    {\r\n        ROSConnection.GetOrCreateInstance().RegisterPublisher<ImageMsg>(topicName);\r\n        InvokeRepeating("TakeSnapshot", 0f, 0.033f); // 30 FPS\r\n    }\r\n\r\n    void TakeSnapshot()\r\n    {\r\n        // Capture camera image\r\n        RenderTexture currentRT = RenderTexture.active;\r\n        RenderTexture.active = targetCamera.targetTexture;\r\n        targetCamera.Render();\r\n\r\n        Texture2D image = new Texture2D(targetCamera.pixelWidth, targetCamera.pixelHeight, TextureFormat.RGB24, false);\r\n        image.ReadPixels(new Rect(0, 0, targetCamera.pixelWidth, targetCamera.pixelHeight), 0, 0);\r\n        image.Apply();\r\n\r\n        RenderTexture.active = currentRT;\r\n\r\n        // Convert to ROS image message\r\n        ImageMsg rosImage = new ImageMsg();\r\n        rosImage.height = (uint)image.height;\r\n        rosImage.width = (uint)image.width;\r\n        rosImage.encoding = "rgb8";  // RGB format\r\n        rosImage.step = (uint)(image.width * 3);  // 3 bytes per pixel\r\n        rosImage.data = image.GetRawTextureData();\r\n\r\n        ROSConnection.GetOrCreateInstance().Send(topicName, rosImage);\r\n    }\r\n}```\r\n\r\n## Domain Randomization\r\n\r\nTo bridge the sim-to-real gap, randomly vary your training data:\r\n\r\n```csharp\r\n// Vary lighting intensity\r\nlight.intensity = Random.Range(0.3f, 1.2f);\r\n\r\n// Move camera position slightly\r\ntargetCamera.transform.Rotate(\r\n    Random.Range(-10f, 10f),\r\n    Random.Range(-5f, 5f),\r\n    0f\r\n);\r\n\r\n// Change prop positions\r\nforeach (GameObject box in warehouseBoxes)\r\n{\r\n    Vector3 randomPos = new Vector3(\r\n        Random.Range(-10f, 10f),\r\n        0.5f,\r\n        Random.Range(-10f, 10f)\r\n    );\r\n    box.transform.position = randomPos;\r\n}```\r\n\r\n## Human-Robot Interaction\r\n\r\nUnity excels at human simulation. Create a human avatar:\r\n\r\n```csharp\r\npublic class HumanController : MonoBehaviour\r\n{\r\n    [Header("Gesture Recognition")]\r\n    [SerializeField] string gestureTopic = "/gesture_commands";\r\n\r\n    public enum Gestures\r\n    {\r\n        Stop = 0,\r\n        Go = 1,\r\n        TurnLeft = 2,\r\n        TurnRight = 3\r\n    }\r\n\r\n    public void PlayGesture(Gestures gesture)\r\n    {\r\n        // Trigger avatar animation\r\n        animator.SetInteger("GestureState", (int)gesture);\r\n\r\n        // Send gesture to robot\r\n        UInt32Msg gestureMsg = new UInt32Msg{\r\n            data = (uint)gesture\r\n        };\r\n        ROSConnection.GetOrCreateInstance().Send(gestureTopic, gestureMsg);\r\n    }\r\n}```\r\n\r\n## Testing Your Visual Environment\r\n\r\n1. **Start Unity**: Open your RobotVisionTraining project\r\n2. **Add Cameron**: Attach the CameraPublisher script to your camera\r\n3. **Build a scene**: With robot, camera, and boxes\r\n4. **Test data flow**: Ensure images publish to ROS2 topic\r\n5. **Train a model**: Use the generated data with your algorithm\r\n\r\n## Quick Verification\r\n\r\nIn Unity Console, you should see:\n'})}),"\n",(0,t.jsx)(n.p,{children:"[INFO] Connected to ROS at localhost:10000\r\n[INFO] Publishing /camera/image at 30fps\r\n[INFO] Snapshot 1/100 taken: 1920x1080 RGB\r\n[INFO] Ready for training..."}),"\n",(0,t.jsx)(n.pre,{children:(0,t.jsx)(n.code,{children:"\r\nAnd in ROS terminal:\r\n```bash\r\nrostopic echo /camera/image\n"})}),"\n",(0,t.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,t.jsxs)(n.ul,{children:["\n",(0,t.jsx)(n.li,{children:"Unity generates infinite, labeled training data"}),"\n",(0,t.jsx)(n.li,{children:"Randomization prevents overfitting to simulation"}),"\n",(0,t.jsx)(n.li,{children:"ROS2 integration brings simulation and reality together"}),"\n",(0,t.jsx)(n.li,{children:"Use Unity when visual realism is important for your application"}),"\n"]}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.strong,{children:"Next Up"}),": Learn how to integrate both simulation approaches into a complete workflow."]}),"\n",(0,t.jsx)(n.hr,{}),"\n",(0,t.jsxs)(n.p,{children:[(0,t.jsx)(n.em,{children:'Stuck? Unity\'s Package Manager makes adding robot-specific packages easy. Search "robotics" to find the latest tools.'}),'"}\u0dbd line count exceed, please continue...']})]})}function u(e={}){const{wrapper:n}={...(0,a.R)(),...e.components};return n?(0,t.jsx)(n,{...e,children:(0,t.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var r=i(6540);const t={},a=r.createContext(t);function o(e){const n=r.useContext(a);return r.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(t):e.components||t:o(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);