"use strict";(self.webpackChunkhackathon_book=self.webpackChunkhackathon_book||[]).push([[1823],{4041:(e,n,a)=>{a.r(n),a.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>d,frontMatter:()=>s,metadata:()=>i,toc:()=>l});const i=JSON.parse('{"id":"chapter-3-isaac-ai-brain/stereo-setup","title":"Stereo Camera Setup and Calibration for Humanoid VSLAM","description":"This guide walks through configuring stereo cameras specifically for humanoid robot VSLAM applications, focusing on hardware selection, geometric calibration, and Real-time performance validation.","source":"@site/docs/chapter-3-isaac-ai-brain/stereo-setup.md","sourceDirName":"chapter-3-isaac-ai-brain","slug":"/chapter-3-isaac-ai-brain/stereo-setup","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/stereo-setup","draft":false,"unlisted":false,"editUrl":"https://github.com/gurupak/physical-ai-and-humanoid-robotics/tree/main/docs/chapter-3-isaac-ai-brain/stereo-setup.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Isaac ROS VSLAM Implementation","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/isaac-ros-vslam-implementation"},"next":{"title":"VSLAM Integration with Humanoid Navigation Stack","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/vslam-integration"}}');var r=a(4848),t=a(8453);const s={},o="Stereo Camera Setup and Calibration for Humanoid VSLAM",c={},l=[{value:"Hardware Selection for Humanoid VSLAM",id:"hardware-selection-for-humanoid-vslam",level:2},{value:"Camera Requirements Analysis",id:"camera-requirements-analysis",level:3},{value:"Resolution Requirements",id:"resolution-requirements",level:4},{value:"Geometric Precision",id:"geometric-precision",level:4},{value:"Cost-Effective Camera Options",id:"cost-effective-camera-options",level:3},{value:"System Configuration",id:"system-configuration",level:2},{value:"Step 1: Dual Camera Mounting",id:"step-1-dual-camera-mounting",level:3},{value:"Hardware Assembly - Example Photos",id:"hardware-assembly---example-photos",level:3},{value:"Software Setup",id:"software-setup",level:2},{value:"Step 2: Install Isaac ROS Dependencies",id:"step-2-install-isaac-ros-dependencies",level:3},{value:"Step 3: Camera Connection Test",id:"step-3-camera-connection-test",level:3},{value:"Calibration Procedure",id:"calibration-procedure",level:2},{value:"Step 4: Generate Calibration Board",id:"step-4-generate-calibration-board",level:3}];function m(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,t.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"stereo-camera-setup-and-calibration-for-humanoid-vslam",children:"Stereo Camera Setup and Calibration for Humanoid VSLAM"})}),"\n",(0,r.jsx)(n.p,{children:"This guide walks through configuring stereo cameras specifically for humanoid robot VSLAM applications, focusing on hardware selection, geometric calibration, and Real-time performance validation."}),"\n",(0,r.jsx)(n.h2,{id:"hardware-selection-for-humanoid-vslam",children:"Hardware Selection for Humanoid VSLAM"}),"\n",(0,r.jsx)(n.h3,{id:"camera-requirements-analysis",children:"Camera Requirements Analysis"}),"\n",(0,r.jsx)(n.p,{children:"For robust VSLAM on humanoid robots, cameras must meet these critical specifications:"}),"\n",(0,r.jsx)(n.h4,{id:"resolution-requirements",children:"Resolution Requirements"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Minimum"}),": 640\xd7480 @ 30 FPS (entry-level)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Recommended"}),": 1920\xd71080 @ 60 FPS (RTX 3060+)"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Optimal"}),": 3840\xd72160 @ 30-60 FPS (RTX 4090)"]}),"\n"]}),"\n",(0,r.jsx)(n.h4,{id:"geometric-precision",children:"Geometric Precision"}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Baseline accuracy"}),": \u2264 0.1 mm standard deviation"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Synchronization error"}),": \u2264 1 millisecond"]}),"\n",(0,r.jsxs)(n.li,{children:[(0,r.jsx)(n.strong,{children:"Lens distortion"}),": \u2265 50% overlap between views"]}),"\n"]}),"\n",(0,r.jsx)(n.h3,{id:"cost-effective-camera-options",children:"Cost-Effective Camera Options"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-markdown",children:"| Camera Model | Cost | Resolution | Max FPS | RTX Recommended |\n|----------|------|------------|---------|----------------|\n| **RealSense D455** | $250 | 1280\xd7720 | 90 | RTX 3060+ |\n| **ZED Mini** | $450 | 2560\xd7720 | 120 | RTX 4080+ |\n| **Stereolabs ZED X*** | $650 | 3840\xd71080* | 100+ | RTX 4090 |\n| **Dual Logitech Cinematic** | $160 | 1920\xd71080 | 60 | RTX 4060+ |\n"})}),"\n",(0,r.jsx)(n.p,{children:"*For production systems, I recommend ZED X for its CUDA acceleration"}),"\n",(0,r.jsx)(n.h2,{id:"system-configuration",children:"System Configuration"}),"\n",(0,r.jsx)(n.h3,{id:"step-1-dual-camera-mounting",children:"Step 1: Dual Camera Mounting"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",metastring:'title="assemble whichereotype_camera_rig while_assure_synchron\u201d}',children:'#!/bin/bash\n# Hardware Mounting Script for Humanoid Application\n\necho "=== Stereo Camera Hardware Assembly for H1 Humanoid ==="\n\n# Mounting specifications (matches H1 humanoid head position)\nBASELINE=0.12  # 120mm - human-like eye separation\nCAM_HEIGHT=1.6  # At humanoid head level (1.6m)\nCAM_DISTANCE=2.0  # Distance base from humanoid head\n\n# DisAssembly Instructions\nassembly_steps() {\n    echo "1. Position cameras horizontally on mounting bar"\n    echo "   - Mount point: N at $BASELINE"\n    echo "   - Alignment: \xb10.1mm baseline measurement critical"\n    echo "   - Height: $CAM_HEIGHT with \xb12cm precision"\n    echo\n    echo "2. Verify cabling and connections"\n    echo "   - USB3 parallelism for bandwidth"\n    echo "   - Trigger cable for hardware sync"\n    echo "   - Separate USB controllers if possible"\n    echo\n    echo "3. Synchronisation setup"\n    echo "   - Hardware trigger required (not software)"\n    echo "   - Jitter <1ms between frames essential"\n    echo "   - Use PTP (Precision Time Protocol) for software sync"\n}\n\nassembly_steps\n'})}),"\n",(0,r.jsx)(n.h3,{id:"hardware-assembly---example-photos",children:"Hardware Assembly - Example Photos"}),"\n",(0,r.jsx)(n.p,{children:(0,r.jsx)(n.em,{children:"Example: Proper camera alignment for H1 humanoid application (image placeholder)"})}),"\n",(0,r.jsx)(n.h2,{id:"software-setup",children:"Software Setup"}),"\n",(0,r.jsx)(n.h3,{id:"step-2-install-isaac-ros-dependencies",children:"Step 2: Install Isaac ROS Dependencies"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-bash",children:"# Install via apt\nsudo apt update && sudo apt install -y \\\n    ros-humble-isaac-ros-camera \\\n    ros-humble-isaac-ros-image-tools \\\n    ros-humble-isaac-ros-stereo \\\n    ros-humble-stereo-msgs \\\n    ros-humble-image-geometry \\\n    ros-humble-camera-calibration\n\n# Install calibration utilities\nsudo apt install -y \\\n    python3-opencv \\\n    python3-pykml \\\n    ros-humble-sensor-msgs \\\n    ros-humble-isaac-ros-camera-calibration\n"})}),"\n",(0,r.jsx)(n.h3,{id:"step-3-camera-connection-test",children:"Step 3: Camera Connection Test"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="camera_connection_test.py"',children:'import cv2\nimport numpy as np\ndeftest_camera_connection():\n    """Test stereo camera hardware functionality for humanoid application"""\n\n    # Test basic connectivity\n    left = cv2.VideoCapture()  # left_cam = 0\n    right = cv2.VideoCapture()  # right_cam = 1\n\n    # Verify capture\n    success, left_frame = left.read()\n    success_right, right_frame = right.read()\n\n    assert success and success_right, "Camera hardware test failed"\n\n    print(f"Left camera: {left_frame.shape} @ {int(left.get(cv2.CAP_PROP_FPS))} FPS")\n    print(f"Right camera: {right_frame.shape} @ {int(right.get(cv2.CAP_PROP_FPS))} FPS")\n\n    # Verify synchronization\n    import time\n    start_time = time.time()\n    elapsed = 0\n    max_frames = 100\n\n    frame_counter = 0\n    while elapsed < 30:  # 30 second test\n        left_success = left.grab()\n        right_success = right.grab()\n        if left_success and right_success:\n            frame_counter += 1\n        else:\n            print("\u23f3 Synchronization issue detected")\n\n        elapsed = time.time() - start_time\n\n    print(f"Captured {frame_counter} synchronized pairs in {elapsed:.1f} seconds")\n    print(f"Synchronization rate: {frame_counter/elapsed:.1f} FPS")\n\n    return frame_counter >= (max_frames * 0.95)  # 95% sync test\n\n# Run test\nif __name__ == "__main__":\n    if test_camera_connection():\n        print("\\n\u2705 Camera hardware test PASSED")\n    else:\n        print("\\n\u274c Camera hardware test FAILED (recommended replace)")\n'})}),"\n",(0,r.jsx)(n.h2,{id:"calibration-procedure",children:"Calibration Procedure"}),"\n",(0,r.jsx)(n.h3,{id:"step-4-generate-calibration-board",children:"Step 4: Generate Calibration Board"}),"\n",(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-python",metastring:'title="create_calibration_board_for_humanoid.py"',children:'import numpy as np\nimport cv2\nfrom PIL import Image, ImageDraw\n\ndef create_flat_calibration_board_suitable_for_humanoid_workspace(pattern_type="checkerboard",\n                                                                  board_size=(9, 6),\n                                                                  square_size_cm=2.5,\n                                                                  working_area="1.2m"):\n    """Creates calibration target suitable for\n'})})]})}function d(e={}){const{wrapper:n}={...(0,t.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}},8453:(e,n,a)=>{a.d(n,{R:()=>s,x:()=>o});var i=a(6540);const r={},t=i.createContext(r);function s(e){const n=i.useContext(t);return i.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:s(e.components),i.createElement(t.Provider,{value:n},e.children)}}}]);