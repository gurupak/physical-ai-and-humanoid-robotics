"use strict";(self.webpackChunkhackathon_book=self.webpackChunkhackathon_book||[]).push([[6815],{6592:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>c,contentTitle:()=>o,default:()=>u,frontMatter:()=>s,metadata:()=>t,toc:()=>l});const t=JSON.parse('{"id":"chapter-3-isaac-ai-brain/scene-creation","title":"Scene Creation Tutorial","description":"Quick Start (15-minute photorealistic warehouse)","source":"@site/docs/chapter-3-isaac-ai-brain/scene-creation.md","sourceDirName":"chapter-3-isaac-ai-brain","slug":"/chapter-3-isaac-ai-brain/scene-creation","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/scene-creation","draft":false,"unlisted":false,"editUrl":"https://github.com/gurupak/physical-ai-and-humanoid-robotics/tree/main/docs/chapter-3-isaac-ai-brain/scene-creation.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Synthetic Data Generation with Isaac Sim","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/synthetic-data-overview"},"next":{"title":"Prerequisites - Chapter 3: The AI-Robot Brain","permalink":"/physical-ai-and-humanoid-robotics/docs/chapter-3-isaac-ai-brain/prerequisites"}}');var a=i(4848),r=i(8453);const s={},o="Scene Creation Tutorial",c={},l=[{value:"Quick Start (15-minute photorealistic warehouse)",id:"quick-start-15-minute-photorealistic-warehouse",level:2},{value:"Step 1: Launch Isaac Sim with Template (30 seconds)",id:"step-1-launch-isaac-sim-with-template-30-seconds",level:3},{value:"Step 2: Add Humanoid Robot (2 minutes)",id:"step-2-add-humanoid-robot-2-minutes",level:3},{value:"Step 3: Configure Lighting for AI Training (3 minutes)",id:"step-3-configure-lighting-for-ai-training-3-minutes",level:3},{value:"Step 4: Add Functional Objects (3 minutes)",id:"step-4-add-functional-objects-3-minutes",level:3},{value:"Step 5: Position Cameras for Training (4 minutes)",id:"step-5-position-cameras-for-training-4-minutes",level:3}];function h(e){const n={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",p:"p",pre:"pre",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"scene-creation-tutorial",children:"Scene Creation Tutorial"})}),"\n",(0,a.jsx)(n.h2,{id:"quick-start-15-minute-photorealistic-warehouse",children:"Quick Start (15-minute photorealistic warehouse)"}),"\n",(0,a.jsx)(n.p,{children:"This tutorial creates your first photorealistic warehouse scene with H1 humanoid robot, ready for training computer vision models."}),"\n",(0,a.jsx)(n.h3,{id:"step-1-launch-isaac-sim-with-template-30-seconds",children:"Step 1: Launch Isaac Sim with Template (30 seconds)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-bash",children:'# Start Isaac Sim in simulation-friendly mode\n./isaac-sim.sh \\\n  --load-scene="/Isaac/Environments/Simple_Warehouse/warehouse_multiple_shelves.usd" \\\n  --no-window \\\n  --simulate-continuous \\\n  --headless > launch.log 2>&1\n\n# Verify successful launch\ngrep "Warehouse scene loaded" launch.log\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-2-add-humanoid-robot-2-minutes",children:"Step 2: Add Humanoid Robot (2 minutes)"}),"\n",(0,a.jsx)(n.p,{children:"Using the Isaac Sim Python API:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="warehouse_scene_setup.py - minimal approach"',children:'import omni.isaac.core.utils.prims as prim_utils\nimport omni.isaac.core.utils.numpy as np_utils\nfrom pxr import UsdGeom, Gf\n\ndef create_warehouse_with_humanoid():\n    # Get the stage\n    stage = omni.usd.get_context().get_stage()\n\n    # Add H1 humanoid at warehouse origin\n    humanoid_path = "/World/humanoid_h1"\n    prim_utils.create_prim(\n        prim_path=humanoid_path,\n        usd_path="/Isaac/Robots/Unitree/H1/h1.usd",\n        translation=(0, 0, 0)\n    )\n\n    # Position humanoid naturally near work area\n    prim_utils.set_prim_property(\n        prim_path + "/skeleton_root"\n        property_name="xformOp:translate",\n        value=Gf.Vec3f(2.0, 0.0, 0.0)  # 2 meters ahead\n    )\n\n    # Set canonical humanoid height\n    prim_utils.set_prim_property(\n        humanoid_path,\n        property_name="xformOp:scale",\n        value=Gf.Vec3f(1.0, 1.0, 1.0)\n    )\n\n    return humanoid_path\n\ncreate_warehouse_with_humanoid()  # Execute\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-3-configure-lighting-for-ai-training-3-minutes",children:"Step 3: Configure Lighting for AI Training (3 minutes)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="scene_lighting_configuration.py"',children:'import omni.isaac.core.utils.prims as prim_utils\nfrom pxr import Usd\nfrom pxr import UsdLux\n\ndef setup_warehouse_lighting():\n    # Remove default omniverse lights\n    stage = omni.usd.get_context().get_stage()\n\n    # Add area lights for realistic warehouse illumination\n    light_types = [\n        ("/World/Light1", "_sky_light"),  # Soft ambient lighting\n        ("/World/Light2", "_overhead_light"),\n        ("/World/Light3", "_ambient_bounce")\n    ]\n\n    for light_name, light_type in light_types:\n        usd_light = UsdLux.SphereLight.Define(stage, light_name)\n        usd_light.CreateRadiusAttr(0.5)\n\n        if light_type == "_sky_light":\n            usd_light.CreateColorAttr((1.0, 1.0, 1.05))  # Cool white\n            usd_light.CreateIntensityAttr(5000)  # 500W area equivalent\n\n        elif light_type == "_overhead_light":\n            usd_light.CreateColorAttr((1.02, 1.0, 0.98))  # Slight warm    BSD window\n            usd_light.CreateIntensityAttr(8000)  # Main workplace illumination\n\n        elif light_type == "_ambient_bounce":\n            usd_light.CreateColorAttr((0.98, 0.98, 1.02))  # Blue bounce from walls\n            usd_light.CreateIntensityAttr(3000)\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-4-add-functional-objects-3-minutes",children:"Step 4: Add Functional Objects (3 minutes)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="add_working_objects.py"',children:'def populate_warehouse_objects():\n    # Realistic working environment objects\n    objects_config = [\n        {\n            "path": "/World/object_weighing_pallet",\n            "type": "pallet",\n            "position": (3.5, -1.0, 0.15),  # naturally in humanoid workspace\n            "variants": [\n                "/Isaac/Assets/SimReady/Standard/Engineering/cajaPileBox.usd",\n                "/Isaac/Assets/SimReady/Standard/Engineering/greenCrate.usd"\n            ]\n        },\n        {\n            "path": "/World/work_sampling_tools",\n            "type": "tools",\n            "position": (2.5, 2.0, 0.6),\n            "variants": "/Isaac/Assets/SimReady/Standard/Engineering/toolsBox.usd"\n        }\n    ]\n\n    for obj_config in objects_config:\n        # Random variant selection\n        import random\n        selected_variant = random.choice(obj_config["variants"])\n\n        # Create object instance\n        prim_utils.create_prim(\n            obj_config["path"],\n            usd_path=selected_variant,\n            translation=obj_config["position"],\n            scale=(0.5, 0.5, 0.5)  # Adjust size for H1 humanoid scale\n        )\n'})}),"\n",(0,a.jsx)(n.h3,{id:"step-5-position-cameras-for-training-4-minutes",children:"Step 5: Position Cameras for Training (4 minutes)"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-python",metastring:'title="instrument_camera}.py" This creates camera setup for CV training as per chapter 3 requirements',children:'\nimport omni.isaac.core.utils.prims as prim_utils\nimport carb\nimport numpy as np\n\ndef configure_training_cameras():\n    """\n    Configure stereo camera rig for humanoid robot training\n    Matches H1 humanoid head position and orientation\n    """\n\n    # Humanoid head position (maintains natural perspective)\n    base_height = 1.6  # H1 natural height\n\n    def create_camera_config(name, relative_pos):\n        """Helper to create camera rig configurations"""\n\n        # Stereo baseline - human-like spacing\n        baseline = 0.12  # 12cm - natural human eye separation\n\n        # Primary viewpoint from humanoid head perspectives\n        if name == "left_head_camera":\n            pos = (0.0, baseline/2, base_height)\n        elif name == "right_head_camera":\n            pos = (0.0, -baseline/2, base_height)\n        else:  # Overview camera\n            pos = (-2.0, 0.5, base_height+0.3)\n\n        # Apply relative offset\n        offset = np.array(relative_pos)\n\n        return tuple(np.array(pos) + offset)\n\n    # Camera rig configurations for different training viewpoints\n    camera_configs = {\n        "object_detection": [\n            ("left_head_camera", (0.15, 0.0, 0.12)),\n            ("right_head_camera", (0.15, 0.0, 0.12)),\n            ("overview_camera", (0.0, 0.0, 0.0))  # Static overview\n        ],\n        "navigation": [\n            ("nav_eye_left", (0.0, 0.06, base_height-0.02)),\n            ("nav_eye_right", (0.0, -0.06, base_height-0.02)),\n            ("nav_chest", (-0.1, 0.0, base_height-0.3))  # Chest-level obstacle view\n        ]\n    }\n\n    # Process camera configurations\n    cameras = []\n    for config_name, positions in camera_configs.items():\n        for cam_name, rel_pos in positions:\n            camera_path    US1 summary with quiz and outcomes"}].file_path is not a valid parameter of Write:0. "file_path" is None\n'})})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(h,{...e})}):h(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>s,x:()=>o});var t=i(6540);const a={},r=t.createContext(a);function s(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function o(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);