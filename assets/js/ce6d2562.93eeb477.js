"use strict";(self.webpackChunkhackathon_book=self.webpackChunkhackathon_book||[]).push([[9482],{2552:(e,n,i)=>{i.r(n),i.d(n,{assets:()=>l,contentTitle:()=>s,default:()=>u,frontMatter:()=>o,metadata:()=>t,toc:()=>c});const t=JSON.parse('{"id":"module-2-digital-twin/unity-rendering/unity-rendering","title":"03. Visual Simulation with Unity","description":"Build photorealistic environments for computer vision and human-robot interaction","source":"@site/docs/module-2-digital-twin/03-unity-rendering/index.md","sourceDirName":"module-2-digital-twin/03-unity-rendering","slug":"/module-2-digital-twin/unity-rendering/","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/unity-rendering/","draft":false,"unlisted":false,"editUrl":"https://github.com/gurupak/physical-ai-and-humanoid-robotics/tree/main/docs/module-2-digital-twin/03-unity-rendering/index.md","tags":[],"version":"current","frontMatter":{"id":"unity-rendering","title":"03. Visual Simulation with Unity","description":"Build photorealistic environments for computer vision and human-robot interaction","sidebar_label":"03. Unity Visuals","readingTime":25},"sidebar":"tutorialSidebar","previous":{"title":"02. Gazebo Physics","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/gazebo-physics/"},"next":{"title":"04. Integration Best Practices","permalink":"/physical-ai-and-humanoid-robotics/docs/module-2-digital-twin/integration"}}');var a=i(4848),r=i(8453);const o={id:"unity-rendering",title:"03. Visual Simulation with Unity",description:"Build photorealistic environments for computer vision and human-robot interaction",sidebar_label:"03. Unity Visuals",readingTime:25},s="03. Visual Simulation with Unity",l={},c=[{value:"Why Visual Simulation Matters",id:"why-visual-simulation-matters",level:2},{value:"Setting Up Your First Unity Project",id:"setting-up-your-first-unity-project",level:2},{value:"1. Create a New Unity Project",id:"1-create-a-new-unity-project",level:3},{value:"2. Import the Robotics Package",id:"2-import-the-robotics-package",level:3},{value:"3. The Simplest Scene Setup",id:"3-the-simplest-scene-setup",level:3},{value:"4. Add Some Props",id:"4-add-some-props",level:3},{value:"Training Data Generation",id:"training-data-generation",level:2},{value:"Key Takeaways",id:"key-takeaways",level:2}];function d(e){const n={code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",header:"header",hr:"hr",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,r.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(n.header,{children:(0,a.jsx)(n.h1,{id:"03-visual-simulation-with-unity",children:"03. Visual Simulation with Unity"})}),"\n",(0,a.jsx)(n.p,{children:"Unity creates stunning visual environments that look like real camera footage. This is perfect for training AI systems and human collaborations."}),"\n",(0,a.jsx)(n.h2,{id:"why-visual-simulation-matters",children:"Why Visual Simulation Matters"}),"\n",(0,a.jsx)(n.p,{children:"Real computer vision training data is expensive:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Cameras cost hundreds or thousands of dollars"}),"\n",(0,a.jsx)(n.li,{children:"Manually labeling thousands of images takes weeks"}),"\n",(0,a.jsx)(n.li,{children:"Lighting conditions are hard to control"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:["Unity solves this: ",(0,a.jsx)(n.strong,{children:"Generate unlimited perfect training data instantly."})]}),"\n",(0,a.jsx)(n.h2,{id:"setting-up-your-first-unity-project",children:"Setting Up Your First Unity Project"}),"\n",(0,a.jsx)(n.h3,{id:"1-create-a-new-unity-project",children:"1. Create a New Unity Project"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Install Unity Hub if you haven't already"}),"\n",(0,a.jsx)(n.li,{children:"Create a new 3D project with Universal Render Pipeline (URP)"}),"\n",(0,a.jsx)(n.li,{children:'Name it "RobotVisionTraining"'}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"2-import-the-robotics-package",children:"2. Import the Robotics Package"}),"\n",(0,a.jsx)(n.p,{children:"Unity has official robotics support:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:"// Package Manager -> Add package from Git URL\ncom.unity.robotics.ros-tcp-connector\n"})}),"\n",(0,a.jsx)(n.h3,{id:"3-the-simplest-scene-setup",children:"3. The Simplest Scene Setup"}),"\n",(0,a.jsx)(n.p,{children:"Create a basic warehouse scene:"}),"\n",(0,a.jsxs)(n.ol,{children:["\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Floor"}),": GameObject -> 3D Object -> Plane (scale 10x10)"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Robot"}),": Right-click in Hierarchy -> Import Camera"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Lighting"}),": Window -> Rendering -> Lighting Settings"]}),"\n",(0,a.jsxs)(n.li,{children:[(0,a.jsx)(n.strong,{children:"Camera"}),": Position 5 meters above ground, look down"]}),"\n"]}),"\n",(0,a.jsx)(n.h3,{id:"4-add-some-props",children:"4. Add Some Props"}),"\n",(0,a.jsx)(n.p,{children:"Instantiate a few boxes from Unity Asset Store:"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Get free Robot Factory assets"}),"\n",(0,a.jsx)(n.li,{children:"Add 5-10 cardboard boxes"}),"\n",(0,a.jsx)(n.li,{children:"Position randomly around the floor"}),"\n"]}),"\n",(0,a.jsx)(n.h2,{id:"training-data-generation",children:"Training Data Generation"}),"\n",(0,a.jsx)(n.p,{children:"With Unity ROS, stream camera data directly to ROS2:"}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{className:"language-csharp",children:'using Unity.Robotics.ROSTCPConnector;\nusing Unity.Robotics.ROSTCPConnector.ROSGeometry;\n\npublic class CameraPublisher : MonoBehaviour\n{\n    [SerializeField] Camera targetCamera;\n    [SerializeField] string topicName = "/camera/image";\n    [SerializeField] string frameId = "camera_link";\n\n    void Start()\n    {\n        ROSConnection.GetOrCreateInstance().RegisterPublisher<ImageMsg>(topicName);\n        InvokeRepeating("TakeSnapshot", 0f, 0.033f); // 30 FPS\n    }\n\n    void TakeSnapshot()\n    {\n        // Capture camera image\n        RenderTexture currentRT = RenderTexture.active;\n        RenderTexture.active = targetCamera.targetTexture;\n        targetCamera.Render();\n\n        Texture2D image = new Texture2D(targetCamera.pixelWidth, targetCamera.pixelHeight, TextureFormat.RGB24, false);\n        image.ReadPixels(new Rect(0, 0, targetCamera.pixelWidth, targetCamera.pixelHeight), 0, 0);\n        image.Apply();\n\n        RenderTexture.active = currentRT;\n\n        // Convert to ROS image message\n        ImageMsg rosImage = new ImageMsg();\n        rosImage.height = (uint)image.height;\n        rosImage.width = (uint)image.width;\n        rosImage.encoding = "rgb8";  // RGB format\n        rosImage.step = (uint)(image.width * 3);  // 3 bytes per pixel\n        rosImage.data = image.GetRawTextureData();\n\n        ROSConnection.GetOrCreateInstance().Send(topicName, rosImage);\n    }\n}```\n\n## Domain Randomization\n\nTo bridge the sim-to-real gap, randomly vary your training data:\n\n```csharp\n// Vary lighting intensity\nlight.intensity = Random.Range(0.3f, 1.2f);\n\n// Move camera position slightly\ntargetCamera.transform.Rotate(\n    Random.Range(-10f, 10f),\n    Random.Range(-5f, 5f),\n    0f\n);\n\n// Change prop positions\nforeach (GameObject box in warehouseBoxes)\n{\n    Vector3 randomPos = new Vector3(\n        Random.Range(-10f, 10f),\n        0.5f,\n        Random.Range(-10f, 10f)\n    );\n    box.transform.position = randomPos;\n}```\n\n## Human-Robot Interaction\n\nUnity excels at human simulation. Create a human avatar:\n\n```csharp\npublic class HumanController : MonoBehaviour\n{\n    [Header("Gesture Recognition")]\n    [SerializeField] string gestureTopic = "/gesture_commands";\n\n    public enum Gestures\n    {\n        Stop = 0,\n        Go = 1,\n        TurnLeft = 2,\n        TurnRight = 3\n    }\n\n    public void PlayGesture(Gestures gesture)\n    {\n        // Trigger avatar animation\n        animator.SetInteger("GestureState", (int)gesture);\n\n        // Send gesture to robot\n        UInt32Msg gestureMsg = new UInt32Msg{\n            data = (uint)gesture\n        };\n        ROSConnection.GetOrCreateInstance().Send(gestureTopic, gestureMsg);\n    }\n}```\n\n## Testing Your Visual Environment\n\n1. **Start Unity**: Open your RobotVisionTraining project\n2. **Add Cameron**: Attach the CameraPublisher script to your camera\n3. **Build a scene**: With robot, camera, and boxes\n4. **Test data flow**: Ensure images publish to ROS2 topic\n5. **Train a model**: Use the generated data with your algorithm\n\n## Quick Verification\n\nIn Unity Console, you should see:\n'})}),"\n",(0,a.jsx)(n.p,{children:"[INFO] Connected to ROS at localhost:10000\n[INFO] Publishing /camera/image at 30fps\n[INFO] Snapshot 1/100 taken: 1920x1080 RGB\n[INFO] Ready for training..."}),"\n",(0,a.jsx)(n.pre,{children:(0,a.jsx)(n.code,{children:"\nAnd in ROS terminal:\n```bash\nrostopic echo /camera/image\n"})}),"\n",(0,a.jsx)(n.h2,{id:"key-takeaways",children:"Key Takeaways"}),"\n",(0,a.jsxs)(n.ul,{children:["\n",(0,a.jsx)(n.li,{children:"Unity generates infinite, labeled training data"}),"\n",(0,a.jsx)(n.li,{children:"Randomization prevents overfitting to simulation"}),"\n",(0,a.jsx)(n.li,{children:"ROS2 integration brings simulation and reality together"}),"\n",(0,a.jsx)(n.li,{children:"Use Unity when visual realism is important for your application"}),"\n"]}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.strong,{children:"Next Up"}),": Learn how to integrate both simulation approaches into a complete workflow."]}),"\n",(0,a.jsx)(n.hr,{}),"\n",(0,a.jsxs)(n.p,{children:[(0,a.jsx)(n.em,{children:'Stuck? Unity\'s Package Manager makes adding robot-specific packages easy. Search "robotics" to find the latest tools.'}),'"}\u0dbd line count exceed, please continue...']})]})}function u(e={}){const{wrapper:n}={...(0,r.R)(),...e.components};return n?(0,a.jsx)(n,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}},8453:(e,n,i)=>{i.d(n,{R:()=>o,x:()=>s});var t=i(6540);const a={},r=t.createContext(a);function o(e){const n=t.useContext(r);return t.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function s(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:o(e.components),t.createElement(r.Provider,{value:n},e.children)}}}]);